# ğŸ¦… QuetzalCore Core - Deployment Architecture

## Your Mac = Development Only âŒ No Services Running

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      YOUR MAC (M1)                  â”‚
â”‚  âŒ NO backend running              â”‚
â”‚  âŒ NO Docker running                â”‚
â”‚  âŒ NO services running              â”‚
â”‚                                     â”‚
â”‚  âœ… VS Code (code editing)          â”‚
â”‚  âœ… Git (version control)           â”‚
â”‚  âœ… Deployment scripts              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”‚ git push / deploy scripts
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CLOUD (senasaitech.com)           â”‚
â”‚   âœ… FastAPI Gateway (port 443)     â”‚
â”‚   âœ… SSL Certificate                â”‚
â”‚   âœ… Nginx Reverse Proxy            â”‚
â”‚   âœ… Load Balancer                  â”‚
â”‚                                     â”‚
â”‚   Routes requests to QuetzalCore Core    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”‚ API calls
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   QUETZALCORE CORE (Distributed)         â”‚
â”‚   Master Node: Orchestration        â”‚
â”‚   â”œâ”€ Task queue                     â”‚
â”‚   â”œâ”€ Worker assignment              â”‚
â”‚   â””â”€ Result aggregation             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”‚ Distribute workload
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              QUETZALCORE WORKER NODES                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Worker 1    â”‚ â”‚  Worker 2    â”‚ â”‚  Worker 3    â”‚     â”‚
â”‚  â”‚              â”‚ â”‚              â”‚ â”‚              â”‚     â”‚
â”‚  â”‚ Native HV    â”‚ â”‚ Native HV    â”‚ â”‚ Native HV    â”‚     â”‚
â”‚  â”‚ â”œâ”€ VM Pool   â”‚ â”‚ â”œâ”€ VM Pool   â”‚ â”‚ â”œâ”€ VM Pool   â”‚     â”‚
â”‚  â”‚ â”œâ”€ GPU Sim   â”‚ â”‚ â”œâ”€ GPU Sim   â”‚ â”‚ â”œâ”€ GPU Sim   â”‚     â”‚
â”‚  â”‚ â””â”€ Process   â”‚ â”‚ â””â”€ Process   â”‚ â”‚ â””â”€ Process   â”‚     â”‚
â”‚  â”‚    Isolation â”‚ â”‚    Isolation â”‚ â”‚    Isolation â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Request Flow

### Example: Mining MAG Survey Analysis

```
1. Client uploads survey
   â†“
2. Cloud API (senasaitech.com)
   POST /api/mining/mag-survey
   â†“
3. QuetzalCore Master receives task
   {
     "task_id": "mag_123",
     "type": "mineral_discrimination",
     "data": {...}
   }
   â†“
4. Master assigns to Worker 2
   â†“
5. Worker 2 Native HV creates VM
   - Allocate: 4 CPU cores, 8GB RAM
   - Assign: vGPU with 8,192 threads
   - Isolate: Process namespace
   â†“
6. VM runs computation
   - Load Rust WASM module
   - Process MAG data with GPU sim
   - Compute mineral signatures
   â†“
7. VM returns results to Master
   â†“
8. Master aggregates and returns to Cloud API
   â†“
9. Client receives results
```

---

## Component Locations

### Your Mac
```
/Users/xavasena/hive/
â”œâ”€â”€ backend/                    # Source code
â”‚   â”œâ”€â”€ native_hypervisor.py
â”‚   â”œâ”€â”€ gpu_simulator.py
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ deploy-hv-to-quetzalcore.sh     # Deploy to workers
â””â”€â”€ deploy-to-senasaitech.sh   # Deploy to cloud
```

**Purpose:** Development only. No services run here.

### Cloud Server (senasaitech.com)
```
/var/www/quetzalcore/
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ main.py                # FastAPI gateway only
â”œâ”€â”€ nginx/
â”‚   â””â”€â”€ quetzalcore.conf           # SSL + reverse proxy
â””â”€â”€ logs/
    â””â”€â”€ access.log
```

**Purpose:** Public API gateway, SSL termination, load balancing.

### QuetzalCore Master Node
```
/opt/quetzalcore/
â”œâ”€â”€ master.py                  # Task orchestration
â”œâ”€â”€ task_queue/
â”œâ”€â”€ worker_registry.json
â””â”€â”€ results_cache/
```

**Purpose:** Distribute work to worker nodes, aggregate results.

### QuetzalCore Worker Nodes
```
/opt/quetzalcore/
â”œâ”€â”€ native_hypervisor.py       # â­ RUNS HERE
â”œâ”€â”€ gpu_simulator.py           # â­ RUNS HERE
â”œâ”€â”€ webgpu_driver.py
â”œâ”€â”€ wasm_runtime/
â”‚   â””â”€â”€ *.wasm modules
â””â”€â”€ vm_instances/
    â”œâ”€â”€ vm_0/
    â”œâ”€â”€ vm_1/
    â””â”€â”€ vm_2/
```

**Purpose:** Execute heavy computation in isolated VMs with virtual GPUs.

---

## Deployment Commands

### 1. Deploy Gateway to Cloud
```bash
export SERVER_IP="senasaitech.com"
./deploy-to-senasaitech.sh
```

This deploys:
- FastAPI gateway
- Nginx with SSL
- Load balancer config

### 2. Deploy Hypervisor to QuetzalCore Workers
```bash
export QUETZALCORE_MASTER="master.quetzalcore.local:9000"
export WORKER_NODES="worker1.quetzalcore.local,worker2.quetzalcore.local,worker3.quetzalcore.local"
./deploy-hv-to-quetzalcore.sh
```

This deploys:
- Native hypervisor
- GPU simulator
- WASM runtime
- Systemd service

### 3. Stop Everything on Mac
```bash
# Kill all local processes
pkill -f "uvicorn|python.*backend"

# Stop Docker
docker stop $(docker ps -q)

# Your Mac is now clean âœ…
```

---

## Configuration Files

### Cloud API Gateway (senasaitech.com)
```python
# /var/www/quetzalcore/backend/main.py

from fastapi import FastAPI
import httpx

app = FastAPI()

QUETZALCORE_MASTER = "http://master.quetzalcore.local:9000"

@app.post("/api/mining/mag-survey")
async def mag_survey(data: dict):
    # Forward to QuetzalCore Core
    async with httpx.AsyncClient() as client:
        response = await client.post(
            f"{QUETZALCORE_MASTER}/process",
            json={"task": "mag_survey", "data": data}
        )
        return response.json()
```

### QuetzalCore Master Node
```python
# /opt/quetzalcore/master.py

from fastapi import FastAPI
from backend.distributed_network import QuetzalCoreMaster

app = FastAPI()
master = QuetzalCoreMaster()

@app.post("/process")
async def process_task(task: dict):
    # Assign to worker with HV
    worker_id = master.select_worker()
    result = await master.execute_on_worker(worker_id, task)
    return result
```

### QuetzalCore Worker Node
```python
# /opt/quetzalcore/worker.py

from backend.native_hypervisor import QuetzalCoreHypervisor
from fastapi import FastAPI

app = FastAPI()
hv = QuetzalCoreHypervisor(num_gpus=4)

@app.post("/execute")
async def execute(task: dict):
    # Create VM
    vm = hv.create_vm(
        cpu_cores=4,
        memory_mb=8192,
        gpu_enabled=True
    )
    
    # Run workload
    result = await hv.start_vm(vm.vm_id, task)
    
    # Cleanup
    hv.stop_vm(vm.vm_id)
    
    return result
```

---

## Resource Allocation

### Per Worker Node (Recommended):
- **CPUs:** 16 cores (4 VMs Ã— 4 cores each)
- **RAM:** 64GB (4 VMs Ã— 16GB each)
- **vGPUs:** 4 virtual GPUs (8,192 threads each)
- **Storage:** 500GB SSD

### Per VM Instance:
- **CPUs:** 2-8 cores (configurable)
- **RAM:** 4-16GB (configurable)
- **vGPU:** 1 virtual GPU (8,192 threads)
- **Isolation:** Full process namespace

---

## Monitoring

### Check Worker Status
```bash
# SSH to any worker
ssh quetzalcore@worker1.quetzalcore.local

# Check hypervisor service
systemctl status quetzalcore-hv

# Check running VMs
ps aux | grep "vm_process_worker"

# Check resource usage
htop
```

### Check Master Status
```bash
curl http://master.quetzalcore.local:9000/status
```

Response:
```json
{
  "workers": 3,
  "active_vms": 8,
  "queue_depth": 2,
  "total_cores": 48,
  "total_memory_gb": 192
}
```

### Check Cloud Gateway
```bash
curl https://senasaitech.com/api/health
```

---

## Advantages of This Architecture

### âœ… Your Mac Stays Clean
- No services running
- No resource usage
- Just code editing

### âœ… Scalable Compute
- Add more QuetzalCore workers anytime
- Each worker = 4-8 VMs
- Horizontal scaling

### âœ… Isolated Workloads
- Each VM = isolated process
- Crash in one VM â‰  crash all
- Security boundaries

### âœ… Efficient Resource Usage
- Native processes (not Docker)
- 5-10% overhead (vs Docker 30-50%)
- Virtual GPU simulation

### âœ… Cloud + On-Prem Hybrid
- Cloud: Public API, SSL, auth
- QuetzalCore: Heavy computation, VMs
- Best of both worlds

---

## Next Steps

1. **Set up QuetzalCore worker nodes** (Linux servers/VMs)
2. **Deploy Native HV** to workers with `./deploy-hv-to-quetzalcore.sh`
3. **Deploy API Gateway** to cloud with `./deploy-to-senasaitech.sh`
4. **Configure Master Node** with worker registry
5. **Test end-to-end** MAG survey request

---

## Summary

**Your Mac:** 
- Code only, no services âŒ

**Cloud (senasaitech.com):**
- API gateway, SSL, public access âœ…

**QuetzalCore Core Workers:**
- Native HV, GPU simulator, VMs âœ…â­

**Everything runs on the QuetzalCore network, not your Mac!** ğŸ¦…
