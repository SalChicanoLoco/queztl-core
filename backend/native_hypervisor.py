"""
ü¶Ö QUETZALCORE NATIVE HYPERVISOR
Process-based virtualization without Docker/VMs
Runs directly on QuetzalCore-Core with hardware simulation
"""

import os
import sys
import multiprocessing as mp
import asyncio
import psutil
import signal
import json
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from enum import Enum
import time
import resource

# Import our GPU simulator for virtualized GPU access
try:
    from backend.gpu_simulator import GPUSimulator, QuadLinkedList
    from backend.webgpu_driver import WebGPUDriver
except ImportError:
    GPUSimulator = None
    WebGPUDriver = None


class VirtualResourceType(Enum):
    """Types of virtualized resources"""
    CPU = "cpu"
    MEMORY = "memory"
    GPU = "gpu"
    DISK = "disk"
    NETWORK = "network"


@dataclass
class VirtualMachine:
    """
    Virtual Machine running as native process
    NO Docker, NO VMs - pure process isolation
    """
    vm_id: str
    name: str
    pid: Optional[int] = None
    status: str = "stopped"
    
    # Resource allocation
    cpu_cores: int = 1
    memory_mb: int = 512
    gpu_enabled: bool = False
    
    # Process info
    process: Optional[mp.Process] = None
    
    # Virtual hardware
    virtual_gpu: Optional[Any] = None  # GPUSimulator instance
    memory_namespace: Optional[Dict] = None
    
    # Stats
    start_time: Optional[float] = None
    cpu_usage: float = 0.0
    memory_usage: float = 0.0


class QuetzalCoreHypervisor:
    """
    Native hypervisor that manages VMs as isolated processes
    Uses QuetzalCore-Core's GPU simulator for virtualized GPU access
    """
    
    def __init__(self):
        self.vms: Dict[str, VirtualMachine] = {}
        self.gpu_pool: List[Any] = []  # Pool of virtual GPUs
        self.shared_memory = mp.Manager().dict()
        
    def init_gpu_pool(self, pool_size: int = 4):
        """
        Initialize pool of virtual GPUs
        Each VM can get its own virtualized GPU
        """
        if not GPUSimulator:
            print("‚ö†Ô∏è  GPU Simulator not available")
            return
            
        print(f"üéÆ Initializing {pool_size} virtual GPUs...")
        for i in range(pool_size):
            gpu = GPUSimulator(
                num_blocks=256,
                threads_per_block=32,
                device_name=f"QuetzalCore-vGPU-{i}"
            )
            self.gpu_pool.append(gpu)
            print(f"   ‚úÖ vGPU-{i}: 8,192 threads, {gpu.global_memory.size / (1024**2):.1f} MB")
    
    def create_vm(
        self,
        name: str,
        cpu_cores: int = 1,
        memory_mb: int = 512,
        gpu_enabled: bool = False
    ) -> str:
        """
        Create a new VM (as isolated process)
        Returns VM ID
        """
        import uuid
        vm_id = f"vm-{uuid.uuid4().hex[:8]}"
        
        vm = VirtualMachine(
            vm_id=vm_id,
            name=name,
            cpu_cores=cpu_cores,
            memory_mb=memory_mb,
            gpu_enabled=gpu_enabled
        )
        
        # Allocate virtual GPU if requested
        if gpu_enabled and self.gpu_pool:
            vm.virtual_gpu = self.gpu_pool.pop(0)
            print(f"   üéÆ Allocated vGPU to {name}")
        
        self.vms[vm_id] = vm
        print(f"‚úÖ Created VM: {name} ({vm_id})")
        print(f"   CPU: {cpu_cores} cores, RAM: {memory_mb}MB, GPU: {gpu_enabled}")
        
        return vm_id
    
    def _vm_process_worker(
        self,
        vm_id: str,
        workload_func,
        cpu_cores: int,
        memory_mb: int,
        shared_dict
    ):
        """
        Worker process for VM
        Runs with resource limits (no Docker needed!)
        """
        # Set process resource limits
        try:
            # CPU affinity (bind to specific cores)
            process = psutil.Process()
            available_cpus = list(range(psutil.cpu_count()))
            assigned_cpus = available_cpus[:cpu_cores]
            process.cpu_affinity(assigned_cpus)
            
            # Memory limit (soft limit, not hard)
            max_memory_bytes = memory_mb * 1024 * 1024
            resource.setrlimit(
                resource.RLIMIT_AS,
                (max_memory_bytes, max_memory_bytes * 2)
            )
            
            print(f"   üîí Process {os.getpid()} isolated:")
            print(f"      CPU affinity: {assigned_cpus}")
            print(f"      Memory limit: {memory_mb}MB")
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Resource limits not set: {e}")
        
        # Run the actual workload
        try:
            result = workload_func()
            shared_dict[f"{vm_id}_result"] = result
            shared_dict[f"{vm_id}_status"] = "completed"
        except Exception as e:
            shared_dict[f"{vm_id}_error"] = str(e)
            shared_dict[f"{vm_id}_status"] = "error"
    
    def start_vm(self, vm_id: str, workload_func=None):
        """
        Start a VM (launch process)
        """
        if vm_id not in self.vms:
            raise ValueError(f"VM {vm_id} not found")
        
        vm = self.vms[vm_id]
        
        if vm.status == "running":
            print(f"‚ö†Ô∏è  VM {vm.name} already running")
            return
        
        # Default workload if none provided
        if workload_func is None:
            def default_workload():
                print(f"   üîÑ VM {vm.name} running default workload...")
                time.sleep(2)
                return {"status": "ok", "message": "Workload completed"}
            workload_func = default_workload
        
        # Create isolated process
        vm.process = mp.Process(
            target=self._vm_process_worker,
            args=(
                vm_id,
                workload_func,
                vm.cpu_cores,
                vm.memory_mb,
                self.shared_memory
            ),
            name=f"quetzalcore-vm-{vm.name}"
        )
        
        vm.process.start()
        vm.pid = vm.process.pid
        vm.status = "running"
        vm.start_time = time.time()
        
        print(f"üöÄ Started VM: {vm.name} (PID: {vm.pid})")
    
    def stop_vm(self, vm_id: str, timeout: int = 5):
        """
        Stop a VM gracefully (then force kill if needed)
        """
        if vm_id not in self.vms:
            raise ValueError(f"VM {vm_id} not found")
        
        vm = self.vms[vm_id]
        
        if vm.status != "running" or not vm.process:
            print(f"‚ö†Ô∏è  VM {vm.name} not running")
            return
        
        print(f"üõë Stopping VM: {vm.name} (PID: {vm.pid})...")
        
        # Try graceful shutdown
        vm.process.terminate()
        vm.process.join(timeout=timeout)
        
        # Force kill if still alive
        if vm.process.is_alive():
            print(f"   ‚ö†Ô∏è  Force killing VM {vm.name}")
            vm.process.kill()
            vm.process.join()
        
        vm.status = "stopped"
        vm.pid = None
        
        # Return vGPU to pool
        if vm.virtual_gpu:
            self.gpu_pool.append(vm.virtual_gpu)
            print(f"   üéÆ Returned vGPU to pool")
        
        print(f"‚úÖ Stopped VM: {vm.name}")
    
    def destroy_vm(self, vm_id: str):
        """
        Destroy VM (stop + delete)
        """
        if vm_id not in self.vms:
            raise ValueError(f"VM {vm_id} not found")
        
        vm = self.vms[vm_id]
        
        if vm.status == "running":
            self.stop_vm(vm_id)
        
        del self.vms[vm_id]
        print(f"üóëÔ∏è  Destroyed VM: {vm.name}")
    
    def get_vm_stats(self, vm_id: str) -> Dict[str, Any]:
        """
        Get real-time stats for a VM
        """
        if vm_id not in self.vms:
            raise ValueError(f"VM {vm_id} not found")
        
        vm = self.vms[vm_id]
        
        stats = {
            "vm_id": vm_id,
            "name": vm.name,
            "status": vm.status,
            "pid": vm.pid,
            "cpu_cores": vm.cpu_cores,
            "memory_mb": vm.memory_mb,
            "gpu_enabled": vm.gpu_enabled
        }
        
        # Get process stats if running
        if vm.status == "running" and vm.pid:
            try:
                process = psutil.Process(vm.pid)
                stats["cpu_percent"] = process.cpu_percent(interval=0.1)
                stats["memory_mb_used"] = process.memory_info().rss / (1024 * 1024)
                stats["uptime_seconds"] = time.time() - vm.start_time if vm.start_time else 0
            except psutil.NoSuchProcess:
                stats["status"] = "crashed"
        
        # Get result if completed
        result_key = f"{vm_id}_result"
        if result_key in self.shared_memory:
            stats["result"] = self.shared_memory[result_key]
        
        error_key = f"{vm_id}_error"
        if error_key in self.shared_memory:
            stats["error"] = self.shared_memory[error_key]
        
        return stats
    
    def list_vms(self) -> List[Dict[str, Any]]:
        """
        List all VMs with their stats
        """
        return [self.get_vm_stats(vm_id) for vm_id in self.vms.keys()]
    
    def execute_on_vm(self, vm_id: str, code: str) -> Any:
        """
        Execute Python code on a VM
        (Sandboxed execution in isolated process)
        """
        if vm_id not in self.vms:
            raise ValueError(f"VM {vm_id} not found")
        
        vm = self.vms[vm_id]
        
        if vm.status != "running":
            raise RuntimeError(f"VM {vm.name} not running")
        
        # Create execution namespace
        exec_namespace = {}
        
        # Add virtual GPU if available
        if vm.virtual_gpu:
            exec_namespace['gpu'] = vm.virtual_gpu
        
        # Execute code in sandboxed namespace
        try:
            exec(code, exec_namespace)
            return exec_namespace.get('result', None)
        except Exception as e:
            return {"error": str(e)}


def demo_native_hypervisor():
    """
    Demo: Run VMs without Docker/VMs - pure process isolation
    """
    print("="*70)
    print("ü¶Ö QUETZALCORE NATIVE HYPERVISOR DEMO")
    print("   Process-based virtualization (NO Docker/VMs needed!)")
    print("="*70)
    print()
    
    # Initialize hypervisor
    hv = QuetzalCoreHypervisor()
    
    # Initialize virtual GPU pool
    hv.init_gpu_pool(pool_size=2)
    print()
    
    # Create VMs
    print("üì¶ Creating Virtual Machines...")
    vm1 = hv.create_vm("worker-1", cpu_cores=2, memory_mb=1024, gpu_enabled=True)
    vm2 = hv.create_vm("worker-2", cpu_cores=1, memory_mb=512, gpu_enabled=False)
    print()
    
    # Define workloads
    def cpu_intensive_workload():
        """CPU-bound task"""
        import math
        result = sum([math.sqrt(i) for i in range(1000000)])
        return {"computation": "completed", "result": result}
    
    def gpu_workload():
        """GPU-accelerated task (using our vGPU simulator)"""
        # This would use the virtual GPU
        import numpy as np
        data = np.random.rand(10000, 100)
        result = np.sum(data ** 2)
        return {"gpu_computation": "completed", "result": float(result)}
    
    # Start VMs with workloads
    print("üöÄ Starting VMs...")
    hv.start_vm(vm1, workload_func=gpu_workload)
    hv.start_vm(vm2, workload_func=cpu_intensive_workload)
    print()
    
    # Monitor VMs
    print("üìä Monitoring VMs...")
    time.sleep(3)
    
    for vm_info in hv.list_vms():
        print(f"\n{vm_info['name']}:")
        print(f"   Status: {vm_info['status']}")
        print(f"   PID: {vm_info['pid']}")
        print(f"   CPU: {vm_info.get('cpu_percent', 0):.1f}%")
        print(f"   Memory: {vm_info.get('memory_mb_used', 0):.1f} MB")
        if 'result' in vm_info:
            print(f"   Result: {vm_info['result']}")
    print()
    
    # Stop VMs
    print("üõë Stopping VMs...")
    hv.stop_vm(vm1)
    hv.stop_vm(vm2)
    print()
    
    # Cleanup
    print("üóëÔ∏è  Cleaning up...")
    hv.destroy_vm(vm1)
    hv.destroy_vm(vm2)
    
    print()
    print("="*70)
    print("‚úÖ DEMO COMPLETE")
    print("="*70)


if __name__ == "__main__":
    # Set multiprocessing start method
    mp.set_start_method('spawn', force=True)
    
    demo_native_hypervisor()
