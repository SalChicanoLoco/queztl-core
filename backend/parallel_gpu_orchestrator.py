"""
ðŸš€ QUETZALCORE PARALLEL GPU ORCHESTRATOR
Multiple software GPU units working in parallel to approach real GPU performance

Key Insight: One software GPU = 25% of hardware speed
            Multiple GPUs in parallel = can approach hardware through scaling!
"""

import numpy as np
from typing import List, Dict, Tuple, Any, Callable
from dataclasses import dataclass, field
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import time
from enum import Enum
import queue

from .gpu_simulator import SoftwareGPU
from .gpu_optimizer import SIMDAccelerator, MemoryHierarchyOptimizer

# ============================================================================
# GPU POOL MANAGEMENT
# ============================================================================

class GPUUnitStatus(Enum):
    """Status of a GPU unit"""
    IDLE = "idle"
    BUSY = "busy"
    WARMUP = "warmup"
    STANDBY = "standby"


@dataclass
class GPUUnit:
    """Individual software GPU unit"""
    unit_id: int
    gpu: SoftwareGPU
    status: GPUUnitStatus = GPUUnitStatus.IDLE
    workload: Any = None
    created_at: float = field(default_factory=time.time)
    operations_count: int = 0
    throughput_gflops: float = 0.0
    
    def assign_work(self, workload: Any) -> None:
        """Assign work to this GPU unit"""
        self.status = GPUUnitStatus.BUSY
        self.workload = workload
    
    def complete_work(self) -> None:
        """Mark work as complete"""
        self.status = GPUUnitStatus.IDLE
        self.workload = None
    
    def is_available(self) -> bool:
        """Check if unit is available for work"""
        return self.status in [GPUUnitStatus.IDLE, GPUUnitStatus.STANDBY]


@dataclass
class ParallelGPUTask:
    """Task to be executed on parallel GPU units"""
    task_id: str
    operation: str  # 'matmul', 'conv2d', 'reduce', etc.
    data: np.ndarray
    parameters: Dict[str, Any] = field(default_factory=dict)
    priority: int = 0  # Higher = more important
    result: np.ndarray = None
    completed: bool = False
    execution_time: float = 0.0


class GPUUnitPool:
    """
    Pool of software GPU units on standby, spawned on demand
    
    Strategy:
    - Keep N GPU units warm and ready
    - Spawn additional units for heavy workloads
    - Recycle units after use
    - Load balance work across units
    """
    
    def __init__(self, min_units: int = 2, max_units: int = 8, threads_per_gpu: int = 32):
        self.min_units = min_units
        self.max_units = max_units
        self.threads_per_gpu = threads_per_gpu
        self.units: List[GPUUnit] = []
        self.task_queue: queue.PriorityQueue = queue.PriorityQueue()
        self.executor = ThreadPoolExecutor(max_workers=max_units)
        self.lock = threading.Lock()
        self.shutdown_event = threading.Event()
        
        # Performance tracking
        self.total_tasks_processed = 0
        self.total_throughput = 0.0
        self.avg_latency = 0.0
        
        # Initialize minimum pool
        self._initialize_pool()
    
    def _initialize_pool(self) -> None:
        """Initialize minimum number of GPU units"""
        for i in range(self.min_units):
            gpu = SoftwareGPU(num_blocks=256, threads_per_block=self.threads_per_gpu)
            unit = GPUUnit(unit_id=i, gpu=gpu, status=GPUUnitStatus.STANDBY)
            self.units.append(unit)
    
    def spawn_unit(self) -> GPUUnit:
        """Spawn a new GPU unit (up to max)"""
        with self.lock:
            if len(self.units) < self.max_units:
                gpu = SoftwareGPU(num_blocks=256, threads_per_block=self.threads_per_gpu)
                unit_id = len(self.units)
                unit = GPUUnit(unit_id=unit_id, gpu=gpu, status=GPUUnitStatus.WARMUP)
                self.units.append(unit)
                return unit
            return None
    
    def get_available_unit(self) -> GPUUnit:
        """Get next available GPU unit, spawn if needed"""
        with self.lock:
            # First, try to find idle/standby unit
            for unit in self.units:
                if unit.is_available():
                    return unit
            
            # If none available and room to grow, spawn new unit
            if len(self.units) < self.max_units:
                return self.spawn_unit()
            
            # All units busy - wait for next one to be available
            return None
    
    def get_best_unit(self) -> GPUUnit:
        """Get GPU unit with lowest current utilization"""
        with self.lock:
            available = [u for u in self.units if u.is_available()]
            if available:
                # Return unit with least recent operations
                return min(available, key=lambda u: u.operations_count)
            return None
    
    def submit_task(self, task: ParallelGPUTask) -> None:
        """Submit a task to the queue"""
        # Priority queue: negative priority for higher priority
        self.task_queue.put((-task.priority, task.task_id, task))
    
    def process_tasks(self) -> None:
        """Main loop to process queued tasks"""
        futures = {}
        
        while not self.shutdown_event.is_set():
            try:
                # Get next task (non-blocking with timeout)
                priority, task_id, task = self.task_queue.get(timeout=0.1)
            except queue.Empty:
                continue
            
            # Get available GPU unit
            unit = self.get_best_unit()
            if unit is None:
                # No units available, put task back
                self.task_queue.put((-task.priority, task.task_id, task))
                time.sleep(0.01)
                continue
            
            # Submit task to executor
            unit.assign_work(task)
            future = self.executor.submit(self._execute_task, unit, task)
            futures[future] = (unit, task)
        
        # Clean up completed futures
        for future in as_completed(futures.keys(), timeout=1):
            unit, task = futures[future]
            try:
                future.result()
            except Exception as e:
                print(f"Task {task.task_id} failed: {e}")
    
    def _execute_task(self, unit: GPUUnit, task: ParallelGPUTask) -> None:
        """Execute a task on a GPU unit"""
        start = time.time()
        
        try:
            if task.operation == 'matmul':
                task.result = self._execute_matmul(unit, task)
            elif task.operation == 'conv2d':
                task.result = self._execute_conv2d(unit, task)
            elif task.operation == 'reduce':
                task.result = self._execute_reduce(unit, task)
            else:
                raise ValueError(f"Unknown operation: {task.operation}")
            
            task.completed = True
        finally:
            task.execution_time = time.time() - start
            unit.complete_work()
            unit.operations_count += 1
            self.total_tasks_processed += 1
    
    def _execute_matmul(self, unit: GPUUnit, task: ParallelGPUTask) -> np.ndarray:
        """Execute matrix multiplication on GPU unit"""
        a = task.data
        b = task.parameters.get('b')
        
        # Use SIMD accelerator for speed
        accelerator = SIMDAccelerator()
        result = accelerator.vectorized_matmul(a, b)
        
        return result
    
    def _execute_conv2d(self, unit: GPUUnit, task: ParallelGPUTask) -> np.ndarray:
        """Execute 2D convolution on GPU unit"""
        data = task.data
        kernel = task.parameters.get('kernel')
        
        accelerator = SIMDAccelerator()
        result = accelerator.vectorized_conv2d(data, kernel)
        
        return result
    
    def _execute_reduce(self, unit: GPUUnit, task: ParallelGPUTask) -> np.ndarray:
        """Execute reduction operation on GPU unit"""
        data = task.data
        operation = task.parameters.get('operation', 'sum')
        
        accelerator = SIMDAccelerator()
        result = accelerator.vectorized_reduce(data, operation)
        
        return result
    
    def shutdown(self) -> None:
        """Shutdown all GPU units"""
        self.shutdown_event.set()
        self.executor.shutdown(wait=True)
    
    def get_status(self) -> Dict[str, Any]:
        """Get current pool status"""
        with self.lock:
            idle = sum(1 for u in self.units if u.status == GPUUnitStatus.IDLE)
            busy = sum(1 for u in self.units if u.status == GPUUnitStatus.BUSY)
            standby = sum(1 for u in self.units if u.status == GPUUnitStatus.STANDBY)
        
        return {
            "total_units": len(self.units),
            "idle_units": idle,
            "busy_units": busy,
            "standby_units": standby,
            "max_units": self.max_units,
            "tasks_processed": self.total_tasks_processed,
            "utilization": busy / len(self.units) if self.units else 0
        }


# ============================================================================
# PARALLEL WORK DISTRIBUTION
# ============================================================================

class TaskPartitioner:
    """
    Partition large tasks across multiple GPU units
    
    Strategies:
    - Matrix tiling for matmul
    - 2D tiling for conv2d
    - Data partitioning for reduce
    """
    
    @staticmethod
    def partition_matmul(
        a: np.ndarray,
        b: np.ndarray,
        num_partitions: int = 4
    ) -> List[Tuple[np.ndarray, np.ndarray]]:
        """
        Partition matrix multiply across units
        Split a into row chunks, b stays same
        """
        m, k = a.shape
        rows_per_partition = m // num_partitions
        
        partitions = []
        for i in range(num_partitions):
            start = i * rows_per_partition
            if i == num_partitions - 1:
                end = m
            else:
                end = (i + 1) * rows_per_partition
            
            a_partition = a[start:end, :]
            partitions.append((a_partition, b))
        
        return partitions
    
    @staticmethod
    def partition_conv2d(
        data: np.ndarray,
        kernel: np.ndarray,
        num_partitions: int = 4
    ) -> List[Tuple[np.ndarray, np.ndarray]]:
        """
        Partition 2D convolution across units
        Split data spatially with overlap for kernel
        """
        h, w = data.shape
        kh, kw = kernel.shape
        
        rows_per_partition = h // num_partitions
        overlap = kh - 1
        
        partitions = []
        for i in range(num_partitions):
            start = max(0, i * rows_per_partition - overlap)
            if i == num_partitions - 1:
                end = h
            else:
                end = (i + 1) * rows_per_partition + overlap
            
            data_partition = data[start:end, :]
            partitions.append((data_partition, kernel))
        
        return partitions
    
    @staticmethod
    def partition_reduce(
        data: np.ndarray,
        operation: str = 'sum',
        num_partitions: int = 4
    ) -> List[np.ndarray]:
        """
        Partition reduction across units (sum, min, max, etc)
        Each unit reduces its partition independently
        """
        partitions = np.array_split(data, num_partitions)
        return partitions


# ============================================================================
# RESULT MERGING & COORDINATION
# ============================================================================

class ResultMerger:
    """
    Merge results from parallel GPU units back into final result
    """
    
    @staticmethod
    def merge_matmul_results(partitions: List[np.ndarray]) -> np.ndarray:
        """
        Merge matmul results from row partitions
        Stack row partitions back together
        """
        return np.vstack(partitions)
    
    @staticmethod
    def merge_conv2d_results(
        partitions: List[np.ndarray],
        h_original: int,
        kernel_shape: Tuple[int, int]
    ) -> np.ndarray:
        """
        Merge conv2d results from spatial partitions
        Handle overlapping regions correctly
        """
        kh, kw = kernel_shape
        results = []
        
        for i, part in enumerate(partitions):
            # Calculate non-overlapping region of this partition
            if i == 0:
                # First partition - use all rows
                results.append(part)
            elif i == len(partitions) - 1:
                # Last partition - use all remaining rows
                results.append(part)
            else:
                # Middle partitions - skip overlapping rows
                results.append(part[kh-1:, :])
        
        return np.vstack(results)
    
    @staticmethod
    def merge_reduce_results(
        partitions: List[float],
        operation: str = 'sum'
    ) -> float:
        """
        Merge reduce results from partitions
        Apply reduction operation across partition results
        """
        if operation == 'sum':
            return sum(partitions)
        elif operation == 'max':
            return max(partitions)
        elif operation == 'min':
            return min(partitions)
        else:
            raise ValueError(f"Unknown operation: {operation}")


# ============================================================================
# ORCHESTRATOR: Coordinates everything
# ============================================================================

class ParallelGPUOrchestrator:
    """
    Main orchestrator coordinating multiple GPU units
    
    Responsibilities:
    - Partition work across units
    - Load balance
    - Merge results
    - Scale units based on demand
    - Track performance metrics
    """
    
    def __init__(self, min_units: int = 2, max_units: int = 8):
        self.pool = GPUUnitPool(min_units=min_units, max_units=max_units)
        self.partitioner = TaskPartitioner()
        self.merger = ResultMerger()
        self.accelerator = SIMDAccelerator()
        self.optimizer = MemoryHierarchyOptimizer()
        
        # Performance tracking
        self.execution_times = []
        self.throughputs = []
    
    def parallel_matmul(
        self,
        a: np.ndarray,
        b: np.ndarray,
        num_gpu_units: int = None
    ) -> Tuple[np.ndarray, Dict[str, float]]:
        """
        Parallel matrix multiplication across GPU units
        
        Returns: (result, performance_metrics)
        """
        if num_gpu_units is None:
            num_gpu_units = min(4, len(self.pool.units))
        
        start_time = time.time()
        
        # Partition work
        a_partitions = [a[i::num_gpu_units] for i in range(num_gpu_units)]
        
        # Create tasks
        tasks = []
        for i, a_part in enumerate(a_partitions):
            task = ParallelGPUTask(
                task_id=f"matmul_{i}",
                operation='matmul',
                data=a_part,
                parameters={'b': b},
                priority=1
            )
            tasks.append(task)
            self.pool.submit_task(task)
        
        # Wait for all tasks to complete
        while not all(t.completed for t in tasks):
            time.sleep(0.01)
        
        # Merge results
        results = [t.result for t in tasks]
        final_result = self.merger.merge_matmul_results(results)
        
        elapsed = time.time() - start_time
        
        # Calculate metrics
        flops = 2.0 * a.shape[0] * a.shape[1] * b.shape[1]
        gflops = flops / (elapsed * 1e9)
        
        metrics = {
            "elapsed_sec": elapsed,
            "gflops": gflops,
            "num_gpu_units": num_gpu_units,
            "speedup": gflops / 5.6,  # Baseline single GPU GFLOPS
            "efficiency": (gflops / (num_gpu_units * 5.6)) * 100
        }
        
        self.execution_times.append(elapsed)
        self.throughputs.append(gflops)
        
        return final_result, metrics
    
    def parallel_conv2d(
        self,
        data: np.ndarray,
        kernel: np.ndarray,
        num_gpu_units: int = None
    ) -> Tuple[np.ndarray, Dict[str, float]]:
        """
        Parallel 2D convolution across GPU units
        """
        if num_gpu_units is None:
            num_gpu_units = min(4, len(self.pool.units))
        
        start_time = time.time()
        
        # Partition work
        data_partitions = np.array_split(data, num_gpu_units, axis=0)
        
        # Create tasks
        tasks = []
        for i, data_part in enumerate(data_partitions):
            task = ParallelGPUTask(
                task_id=f"conv2d_{i}",
                operation='conv2d',
                data=data_part,
                parameters={'kernel': kernel},
                priority=1
            )
            tasks.append(task)
            self.pool.submit_task(task)
        
        # Wait for completion
        while not all(t.completed for t in tasks):
            time.sleep(0.01)
        
        # Merge results
        results = [t.result for t in tasks]
        final_result = self.merger.merge_conv2d_results(
            results, data.shape[0], kernel.shape
        )
        
        elapsed = time.time() - start_time
        
        # Calculate metrics
        ops = (data.shape[0] - kernel.shape[0] + 1) * (
            data.shape[1] - kernel.shape[1] + 1
        ) * kernel.shape[0] * kernel.shape[1] * 2
        gflops = ops / (elapsed * 1e9)
        
        metrics = {
            "elapsed_sec": elapsed,
            "gflops": gflops,
            "num_gpu_units": num_gpu_units,
            "speedup": gflops / 2.1,  # Baseline single GPU
            "efficiency": (gflops / (num_gpu_units * 2.1)) * 100
        }
        
        return final_result, metrics
    
    def get_pool_status(self) -> Dict[str, Any]:
        """Get current GPU pool status"""
        return self.pool.get_status()
    
    def get_performance_summary(self) -> Dict[str, float]:
        """Get performance summary"""
        if not self.execution_times:
            return {}
        
        return {
            "avg_gflops": np.mean(self.throughputs),
            "max_gflops": np.max(self.throughputs),
            "min_gflops": np.min(self.throughputs),
            "avg_latency_sec": np.mean(self.execution_times),
            "total_operations": len(self.execution_times)
        }
    
    def shutdown(self) -> None:
        """Shutdown orchestrator"""
        self.pool.shutdown()


if __name__ == '__main__':
    print("\nðŸš€ Parallel GPU Orchestrator Test\n" + "="*60)
    
    # Create orchestrator
    orchestrator = ParallelGPUOrchestrator(min_units=2, max_units=4)
    
    print("\nðŸ“Š GPU Pool Status:")
    print(orchestrator.get_pool_status())
    
    # Test parallel matmul
    print("\nâš¡ Testing Parallel Matrix Multiplication...")
    a = np.random.randn(1024, 1024).astype(np.float32)
    b = np.random.randn(1024, 1024).astype(np.float32)
    
    print("\nWith 1 GPU:")
    single_result, single_metrics = orchestrator.parallel_matmul(a, b, num_gpu_units=1)
    print(f"  Performance: {single_metrics['gflops']:.1f} GFLOPS")
    
    print("\nWith 2 GPUs:")
    dual_result, dual_metrics = orchestrator.parallel_matmul(a, b, num_gpu_units=2)
    print(f"  Performance: {dual_metrics['gflops']:.1f} GFLOPS")
    print(f"  Speedup: {dual_metrics['speedup']:.2f}x")
    print(f"  Efficiency: {dual_metrics['efficiency']:.1f}%")
    
    print("\nWith 4 GPUs:")
    quad_result, quad_metrics = orchestrator.parallel_matmul(a, b, num_gpu_units=4)
    print(f"  Performance: {quad_metrics['gflops']:.1f} GFLOPS")
    print(f"  Speedup: {quad_metrics['speedup']:.2f}x")
    print(f"  Efficiency: {quad_metrics['efficiency']:.1f}%")
    
    print("\nâœ… Parallel GPU test complete!")
    orchestrator.shutdown()
